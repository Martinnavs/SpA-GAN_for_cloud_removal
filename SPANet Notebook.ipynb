{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde7137e",
   "metadata": {},
   "source": [
    "# models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50dc124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers.py\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CBR(nn.Module):\n",
    "    def __init__(self, ch0, ch1, bn=True, sample='down', activation=nn.ReLU(True), dropout=False):\n",
    "        super().__init__()\n",
    "        self.bn = bn\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        if sample=='down':\n",
    "            self.c = nn.Conv2d(ch0, ch1, 4, 2, 1)\n",
    "        else:\n",
    "            self.c = nn.ConvTranspose2d(ch0, ch1, 4, 2, 1)\n",
    "        if bn:\n",
    "            self.batchnorm = nn.BatchNorm2d(ch1, affine=True)\n",
    "        if dropout:\n",
    "            self.Dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.c(x)\n",
    "        if self.bn:\n",
    "            h = self.batchnorm(h)\n",
    "        if self.dropout:\n",
    "            h = self.Dropout(h)\n",
    "        if not self.activation is None:\n",
    "            h = self.activation(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class UpSamplePixelShuffle(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, up_scale=2, activation=nn.ReLU(True)):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "\n",
    "        self.c = nn.Conv2d(in_channels=in_ch, out_channels=out_ch*up_scale*up_scale, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.ps = nn.PixelShuffle(up_scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.c(x)\n",
    "        h = self.ps(h)\n",
    "        if not self.activation is None:\n",
    "            h = self.activation(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ad0789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_utils.py\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1 or classname.find('InstanceNorm2d') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "def print_network(net):\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ad38d",
   "metadata": {},
   "source": [
    "## models/dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eca15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dis.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "class _Discriminator(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "\n",
    "        self.c0_0 = CBR(in_ch, 32, bn=False, sample='down', activation=nn.LeakyReLU(0.2, True), dropout=False)\n",
    "        self.c0_1 = CBR(out_ch, 32, bn=False, sample='down', activation=nn.LeakyReLU(0.2, True), dropout=False)\n",
    "        self.c1 = CBR(64, 128, bn=True, sample='down', activation=nn.LeakyReLU(0.2, True), dropout=False)\n",
    "        self.c2 = CBR(128, 256, bn=True, sample='down', activation=nn.LeakyReLU(0.2, True), dropout=False)\n",
    "        self.c3 = CBR(256, 512, bn=True, sample='down', activation=nn.LeakyReLU(0.2, True), dropout=False)\n",
    "        self.c4 = nn.Conv2d(512, 1, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_0 = x[:, :self.in_ch]\n",
    "        x_1 = x[:, self.in_ch:]\n",
    "        h = torch.cat((self.c0_0(x_0), self.c0_1(x_1)), 1)\n",
    "        h = self.c1(h)\n",
    "        h = self.c2(h)\n",
    "        h = self.c3(h)\n",
    "        h = self.c4(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, gpu_ids):\n",
    "        super().__init__()\n",
    "        self.gpu_ids = gpu_ids\n",
    "\n",
    "        self.dis = nn.Sequential(OrderedDict([('dis', _Discriminator(in_ch, out_ch))]))\n",
    "\n",
    "        self.dis.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.gpu_ids:\n",
    "            return nn.parallel.data_parallel(self.dis, x, self.gpu_ids)\n",
    "        else:\n",
    "            return self.dis(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc2f87",
   "metadata": {},
   "source": [
    "## models/gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af961936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPANet\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "# import common\n",
    "\n",
    "###### Layer \n",
    "def conv1x1(in_channels, out_channels, stride = 1):\n",
    "    return nn.Conv2d(in_channels,out_channels,kernel_size = 1,\n",
    "                    stride =stride, padding=0,bias=False)\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride = 1):\n",
    "    return nn.Conv2d(in_channels,out_channels,kernel_size = 3,\n",
    "        stride =stride, padding=1,bias=False)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        m  = OrderedDict()\n",
    "        m['conv1'] = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        m['relu1'] = nn.ReLU(True)\n",
    "        m['conv2'] = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=2, bias=False,dilation=2)\n",
    "        m['relu2'] = nn.ReLU(True)\n",
    "        m['conv3'] = nn.Conv2d(out_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.group1 = nn.Sequential(m)\n",
    "        self.relu= nn.Sequential(nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.group1(x) \n",
    "        return out\n",
    "\n",
    "class irnn_layer(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(irnn_layer,self).__init__()\n",
    "        self.left_weight = nn.Conv2d(in_channels,in_channels,kernel_size=1,stride=1,groups=in_channels,padding=0)\n",
    "        self.right_weight = nn.Conv2d(in_channels,in_channels,kernel_size=1,stride=1,groups=in_channels,padding=0)\n",
    "        self.up_weight = nn.Conv2d(in_channels,in_channels,kernel_size=1,stride=1,groups=in_channels,padding=0)\n",
    "        self.down_weight = nn.Conv2d(in_channels,in_channels,kernel_size=1,stride=1,groups=in_channels,padding=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        _,_,H,W = x.shape\n",
    "        top_left = x.clone()\n",
    "        top_right = x.clone()\n",
    "        top_up = x.clone()\n",
    "        top_down = x.clone()\n",
    "        top_left[:,:,:,1:] = F.relu(self.left_weight(x)[:,:,:,:W-1]+x[:,:,:,1:],inplace=False)\n",
    "        top_right[:,:,:,:-1] = F.relu(self.right_weight(x)[:,:,:,1:]+x[:,:,:,:W-1],inplace=False)\n",
    "        top_up[:,:,1:,:] = F.relu(self.up_weight(x)[:,:,:H-1,:]+x[:,:,1:,:],inplace=False)\n",
    "        top_down[:,:,:-1,:] = F.relu(self.down_weight(x)[:,:,1:,:]+x[:,:,:H-1,:],inplace=False)\n",
    "        return (top_up,top_right,top_down,top_left)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(Attention,self).__init__()\n",
    "        self.out_channels = int(in_channels/2)\n",
    "        self.conv1 = nn.Conv2d(in_channels,self.out_channels,kernel_size=3,padding=1,stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(self.out_channels,self.out_channels,kernel_size=3,padding=1,stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(self.out_channels,4,kernel_size=1,padding=0,stride=1)\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.sigmod(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SAM(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,attention=1):\n",
    "        super(SAM,self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.irnn1 = irnn_layer(self.out_channels)\n",
    "        self.irnn2 = irnn_layer(self.out_channels)\n",
    "        self.conv_in = conv3x3(in_channels,self.out_channels)\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(self.out_channels,self.out_channels,kernel_size=1,stride=1,padding=0)\n",
    "        self.conv2 = nn.Conv2d(self.out_channels*4,self.out_channels,kernel_size=1,stride=1,padding=0)\n",
    "        self.conv3 = nn.Conv2d(self.out_channels*4,self.out_channels,kernel_size=1,stride=1,padding=0)\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        self.attention = attention\n",
    "        if self.attention:\n",
    "            self.attention_layer = Attention(in_channels)\n",
    "        self.conv_out = conv1x1(self.out_channels,1)\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        if self.attention:\n",
    "            weight = self.attention_layer(x)\n",
    "        out = self.conv1(x)\n",
    "        top_up,top_right,top_down,top_left = self.irnn1(out)\n",
    "        \n",
    "        # direction attention\n",
    "        if self.attention:\n",
    "            top_up.mul(weight[:,0:1,:,:])\n",
    "            top_right.mul(weight[:,1:2,:,:])\n",
    "            top_down.mul(weight[:,2:3,:,:])\n",
    "            top_left.mul(weight[:,3:4,:,:])\n",
    "        out = torch.cat([top_up,top_right,top_down,top_left],dim=1)\n",
    "        out = self.conv2(out)\n",
    "        top_up,top_right,top_down,top_left = self.irnn2(out)\n",
    "        \n",
    "        # direction attention\n",
    "        if self.attention:\n",
    "            top_up.mul(weight[:,0:1,:,:])\n",
    "            top_right.mul(weight[:,1:2,:,:])\n",
    "            top_down.mul(weight[:,2:3,:,:])\n",
    "            top_left.mul(weight[:,3:4,:,:])\n",
    "        \n",
    "        out = torch.cat([top_up,top_right,top_down,top_left],dim=1)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu2(out)\n",
    "        mask = self.sigmod(self.conv_out(out))\n",
    "        return mask\n",
    "\n",
    "###### Network\n",
    "class SPANet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SPANet,self).__init__()\n",
    "\n",
    "        self.conv_in = nn.Sequential(\n",
    "            conv3x3(3,32),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "        self.SAM1 = SAM(32,32,1)\n",
    "        self.res_block1 = Bottleneck(32,32)\n",
    "        self.res_block2 = Bottleneck(32,32)\n",
    "        self.res_block3 = Bottleneck(32,32)\n",
    "        self.res_block4 = Bottleneck(32,32)\n",
    "        self.res_block5 = Bottleneck(32,32)\n",
    "        self.res_block6 = Bottleneck(32,32)\n",
    "        self.res_block7 = Bottleneck(32,32)\n",
    "        self.res_block8 = Bottleneck(32,32)\n",
    "        self.res_block9 = Bottleneck(32,32)\n",
    "        self.res_block10 = Bottleneck(32,32)\n",
    "        self.res_block11 = Bottleneck(32,32)\n",
    "        self.res_block12 = Bottleneck(32,32)\n",
    "        self.res_block13 = Bottleneck(32,32)\n",
    "        self.res_block14 = Bottleneck(32,32)\n",
    "        self.res_block15 = Bottleneck(32,32)\n",
    "        self.res_block16 = Bottleneck(32,32)\n",
    "        self.res_block17 = Bottleneck(32,32)\n",
    "        self.conv_out = nn.Sequential(\n",
    "            conv3x3(32,3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv_in(x)\n",
    "        out = F.relu(self.res_block1(out) + out)\n",
    "        out = F.relu(self.res_block2(out) + out)\n",
    "        out = F.relu(self.res_block3(out) + out)\n",
    "        \n",
    "        Attention1 = self.SAM1(out) \n",
    "        out = F.relu(self.res_block4(out) * Attention1  + out)\n",
    "        out = F.relu(self.res_block5(out) * Attention1  + out)\n",
    "        out = F.relu(self.res_block6(out) * Attention1  + out)\n",
    "        \n",
    "        Attention2 = self.SAM1(out) \n",
    "        out = F.relu(self.res_block7(out) * Attention2 + out)\n",
    "        out = F.relu(self.res_block8(out) * Attention2 + out)\n",
    "        out = F.relu(self.res_block9(out) * Attention2 + out)\n",
    "        \n",
    "        Attention3 = self.SAM1(out) \n",
    "        out = F.relu(self.res_block10(out) * Attention3 + out)\n",
    "        out = F.relu(self.res_block11(out) * Attention3 + out)\n",
    "        out = F.relu(self.res_block12(out) * Attention3 + out)\n",
    "        \n",
    "        Attention4 = self.SAM1(out) \n",
    "        out = F.relu(self.res_block13(out) * Attention4 + out)\n",
    "        out = F.relu(self.res_block14(out) * Attention4 + out)\n",
    "        out = F.relu(self.res_block15(out) * Attention4 + out)\n",
    "        \n",
    "        out = F.relu(self.res_block16(out) + out)\n",
    "        out = F.relu(self.res_block17(out) + out)\n",
    "       \n",
    "        out = self.conv_out(out)\n",
    "\n",
    "        return Attention4 , out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, gpu_ids):\n",
    "        super().__init__()\n",
    "        self.gpu_ids = gpu_ids\n",
    "\n",
    "        self.gen = nn.Sequential(OrderedDict([('gen', SPANet())]))\n",
    "\n",
    "        self.gen.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.gpu_ids:\n",
    "            return nn.parallel.data_parallel(self.gen, x, self.gpu_ids)\n",
    "        else:\n",
    "            return self.gen(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ed900",
   "metadata": {},
   "source": [
    "# Main directory (without subdirectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ad4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_manager.py\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "class TrainDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        train_list_file = os.path.join(config.datasets_dir, config.train_list)\n",
    "        # 如果数据集尚未分割，则进行训练集和测试集的分割\n",
    "        if not os.path.exists(train_list_file) or os.path.getsize(train_list_file) == 0:\n",
    "            files = os.listdir(os.path.join(config.datasets_dir, 'ground_truth'))\n",
    "            random.shuffle(files)\n",
    "            n_train = int(config.train_size * len(files))\n",
    "            train_list = files[:n_train]\n",
    "            test_list = files[n_train:]\n",
    "            np.savetxt(os.path.join(config.datasets_dir, config.train_list), np.array(train_list), fmt='%s')\n",
    "            np.savetxt(os.path.join(config.datasets_dir, config.test_list), np.array(test_list), fmt='%s')\n",
    "\n",
    "        self.imlist = np.loadtxt(train_list_file, str)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        t = cv2.imread(os.path.join(self.config.datasets_dir, 'ground_truth', str(self.imlist[index])), 1).astype(np.float32)\n",
    "        x = cv2.imread(os.path.join(self.config.datasets_dir, 'cloudy_image', str(self.imlist[index])), 1).astype(np.float32)\n",
    "\n",
    "        M = np.clip((t-x).sum(axis=2), 0, 1).astype(np.float32)\n",
    "        x = x / 255\n",
    "        t = t / 255\n",
    "        x = x.transpose(2, 0, 1)\n",
    "        t = t.transpose(2, 0, 1)\n",
    "\n",
    "        return x, t, M\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imlist)\n",
    "\n",
    "\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, test_dir, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.test_dir = test_dir\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.test_files = os.listdir(os.path.join(test_dir, 'cloudy_image'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = os.path.basename(self.test_files[index])\n",
    "        \n",
    "        x = cv2.imread(os.path.join(self.test_dir, 'cloudy_image', filename), 1).astype(np.float32)\n",
    "\n",
    "        x = x / 255\n",
    "\n",
    "        x = x.transpose(2, 0, 1)\n",
    "\n",
    "        return x, filename\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.test_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73183896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "\n",
    "\n",
    "def gpu_manage(config):\n",
    "    if config.cuda:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, config.gpu_ids))\n",
    "        config.gpu_ids = list(range(len(config.gpu_ids)))\n",
    "\n",
    "    # print(os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "\n",
    "    if config.manualSeed is None:\n",
    "        config.manualSeed = random.randint(1, 10000)\n",
    "    print('Random Seed: ', config.manualSeed)\n",
    "    random.seed(config.manualSeed)\n",
    "    torch.manual_seed(config.manualSeed)\n",
    "    if config.cuda:\n",
    "        torch.cuda.manual_seed_all(config.manualSeed)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    if torch.cuda.is_available() and not config.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "\n",
    "def save_image(out_dir, x, num, epoch, filename=None):\n",
    "    test_dir = os.path.join(out_dir, 'epoch_{0:04d}'.format(epoch))\n",
    "    if filename is not None:\n",
    "        test_path = os.path.join(test_dir, filename)\n",
    "    else:\n",
    "        test_path = os.path.join(test_dir, 'test_{0:04d}.png'.format(num))\n",
    "\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "    cv2.imwrite(test_path, x)\n",
    "\n",
    "\n",
    "def checkpoint(config, epoch, gen, dis):\n",
    "    model_dir = os.path.join(config.out_dir, 'models')\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "        \n",
    "    net_gen_model_out_path = os.path.join(model_dir, 'gen_model_epoch_{}.pth'.format(epoch))\n",
    "    net_dis_model_out_path = os.path.join(model_dir, 'dis_model_epoch_{}.pth'.format(epoch))\n",
    "    torch.save(gen.state_dict(), net_gen_model_out_path)\n",
    "    torch.save(dis.state_dict(), net_dis_model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_dir))\n",
    "\n",
    "\n",
    "def make_manager():\n",
    "    if not os.path.exists('.job'):\n",
    "        os.makedirs('.job')\n",
    "        with open('.job/job.txt', 'w', encoding='UTF-8') as f:\n",
    "            f.write('0')\n",
    "\n",
    "\n",
    "def job_increment():\n",
    "    with open('.job/job.txt', 'r', encoding='UTF-8') as f:\n",
    "        n_job = f.read()\n",
    "        n_job = int(n_job)\n",
    "    with open('.job/job.txt', 'w', encoding='UTF-8') as f:\n",
    "        f.write(str(n_job + 1))\n",
    "    \n",
    "    return n_job\n",
    "\n",
    "def heatmap(img):\n",
    "    if len(img.shape) == 3:\n",
    "        b,h,w = img.shape\n",
    "        heat = np.zeros((b,3,h,w)).astype('uint8')\n",
    "        for i in range(b):\n",
    "            heat[i,:,:,:] = np.transpose(cv2.applyColorMap(img[i,:,:],cv2.COLORMAP_JET),(2,0,1))\n",
    "    else:\n",
    "        b,c,h,w = img.shape\n",
    "        heat = np.zeros((b,3,h,w)).astype('uint8')\n",
    "        for i in range(b):\n",
    "            heat[i,:,:,:] = np.transpose(cv2.applyColorMap(img[i,0,:,:],cv2.COLORMAP_JET),(2,0,1))\n",
    "    return heat\n",
    "\n",
    "def save_attention_as_heatmap(filename, att):\n",
    "    att_heat = heatmap(att)\n",
    "    cv2.imwrite(filename, att_heat)\n",
    "    print(filename, 'saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a305286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval.py\n",
    "\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as SSIM\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def test(config, test_data_loader, gen, criterionMSE, epoch):\n",
    "    avg_mse = 0\n",
    "    avg_psnr = 0\n",
    "    avg_ssim = 0\n",
    "    for i, batch in enumerate(test_data_loader):\n",
    "        x, t = Variable(batch[0]), Variable(batch[1])\n",
    "        if config.cuda:\n",
    "            x = x.cuda(0)\n",
    "            t = t.cuda(0)\n",
    "\n",
    "        att, out = gen(x)\n",
    "\n",
    "        if epoch % config.snapshot_interval == 0:\n",
    "            h = 1\n",
    "            w = 3\n",
    "            c = 3\n",
    "            width = config.width\n",
    "            height = config.height\n",
    "\n",
    "            allim = np.zeros((h, w, c, width, height))\n",
    "            x_ = x.cpu().numpy()[0]\n",
    "            t_ = t.cpu().numpy()[0]\n",
    "            out_ = out.cpu().numpy()[0]\n",
    "            in_rgb = x_[:3]\n",
    "            t_rgb = t_[:3]\n",
    "            out_rgb = np.clip(out_[:3], 0, 1)\n",
    "            allim[0, 0, :] = in_rgb * 255\n",
    "            allim[0, 1, :] = out_rgb * 255\n",
    "            allim[0, 2, :] = t_rgb * 255\n",
    "            \n",
    "            allim = allim.transpose(0, 3, 1, 4, 2)\n",
    "            allim = allim.reshape((h*height, w*width, c))\n",
    "\n",
    "            save_image(config.out_dir, allim, i, epoch)\n",
    "\n",
    "        mse = criterionMSE(out, t)\n",
    "        psnr = 10 * np.log10(1 / mse.item())\n",
    "\n",
    "        img1 = np.tensordot(out.cpu().numpy()[0, :3].transpose(1, 2, 0), [0.298912, 0.586611, 0.114478], axes=1)\n",
    "        img2 = np.tensordot(t.cpu().numpy()[0, :3].transpose(1, 2, 0), [0.298912, 0.586611, 0.114478], axes=1)\n",
    "        \n",
    "        ssim = SSIM(img1, img2)\n",
    "        avg_mse += mse.item()\n",
    "        avg_psnr += psnr\n",
    "        avg_ssim += ssim\n",
    "    avg_mse = avg_mse / len(test_data_loader)\n",
    "    avg_psnr = avg_psnr / len(test_data_loader)\n",
    "    avg_ssim = avg_ssim / len(test_data_loader)\n",
    "\n",
    "    print(\"===> Avg. MSE: {:.4f}\".format(avg_mse))\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr))\n",
    "    print(\"===> Avg. SSIM: {:.4f} dB\".format(avg_ssim))\n",
    "    \n",
    "    log_test = {}\n",
    "    log_test['epoch'] = epoch\n",
    "    log_test['mse'] = avg_mse\n",
    "    log_test['psnr'] = avg_psnr\n",
    "    log_test['ssim'] = avg_ssim\n",
    "\n",
    "    return log_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdb8ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_report\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class LogReport():\n",
    "    def __init__(self, log_dir, log_name='log'):\n",
    "        self.log_dir = log_dir\n",
    "        self.log_name = log_name\n",
    "        self.log_ = []\n",
    "\n",
    "    def __call__(self, log):\n",
    "        self.log_.append(log)\n",
    "        with open(os.path.join(self.log_dir, self.log_name), 'w', encoding='UTF-8') as f:\n",
    "            json.dump(self.log_, f, indent=4)\n",
    "    \n",
    "    def save_lossgraph(self):\n",
    "        epoch = []\n",
    "        gen_loss = []\n",
    "        dis_loss = []\n",
    "\n",
    "        for l in self.log_:\n",
    "            epoch.append(l['epoch'])\n",
    "            gen_loss.append(l['gen/loss'])\n",
    "            dis_loss.append(l['dis/loss'])\n",
    "\n",
    "        epoch = np.asarray(epoch)\n",
    "        gen_loss = np.asarray(gen_loss)\n",
    "        dis_loss = np.asarray(dis_loss)\n",
    "\n",
    "        plt.plot(epoch, gen_loss)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss_gen')\n",
    "        plt.savefig(os.path.join(self.log_dir, 'lossgraph_gen.pdf'))\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(epoch, dis_loss)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss_dis')\n",
    "        plt.savefig(os.path.join(self.log_dir, 'lossgraph_dis.pdf'))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "class TestReport():\n",
    "    def __init__(self, log_dir, log_name='log_test'):\n",
    "        self.log_dir = log_dir\n",
    "        self.log_name = log_name\n",
    "        self.log_ = []\n",
    "\n",
    "    def __call__(self, log):\n",
    "        self.log_.append(log)\n",
    "        with open(os.path.join(self.log_dir, self.log_name), 'w', encoding='UTF-8') as f:\n",
    "            json.dump(self.log_, f, indent=4)\n",
    "    \n",
    "    def save_lossgraph(self):\n",
    "        epoch = []\n",
    "        mse = []\n",
    "        psnr = []\n",
    "        \n",
    "        for l in self.log_:\n",
    "            epoch.append(l['epoch'])\n",
    "            mse.append(l['mse'])\n",
    "            psnr.append(l['psnr'])\n",
    "\n",
    "        epoch = np.asarray(epoch)\n",
    "        mse = np.asarray(mse)\n",
    "        psnr = np.asarray(psnr)\n",
    "\n",
    "        plt.plot(epoch, mse)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('mse')\n",
    "        plt.savefig(os.path.join(self.log_dir, 'graph_mse.pdf'))\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(epoch, psnr)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('psnr')\n",
    "        plt.savefig(os.path.join(self.log_dir, 'graph_psnr.pdf'))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "077425bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "from attrdict import AttrMap\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.backends import cudnn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def train(config):\n",
    "    gpu_manage(config)\n",
    "\n",
    "    ### DATASET LOAD ###\n",
    "    print('===> Loading datasets')\n",
    "\n",
    "    dataset = TrainDataset(config)\n",
    "    print('dataset:', len(dataset))\n",
    "    train_size = int((1 - config.validation_size) * len(dataset))\n",
    "    validation_size = len(dataset) - train_size\n",
    "    train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])\n",
    "    print('train dataset:', len(train_dataset))\n",
    "    print('validation dataset:', len(validation_dataset))\n",
    "    training_data_loader = DataLoader(dataset=train_dataset, num_workers=config.threads, batch_size=config.batchsize, shuffle=True)\n",
    "    validation_data_loader = DataLoader(dataset=validation_dataset, num_workers=config.threads, batch_size=config.validation_batchsize, shuffle=False)\n",
    "    \n",
    "    ### MODELS LOAD ###\n",
    "    print('===> Loading models')\n",
    "\n",
    "    gen = Generator(gpu_ids=config.gpu_ids)\n",
    "\n",
    "    if config.gen_init is not None:\n",
    "        param = torch.load(config.gen_init)\n",
    "        gen.load_state_dict(param)\n",
    "        print('load {} as pretrained model'.format(config.gen_init))\n",
    "\n",
    "    dis = Discriminator(in_ch=config.in_ch, out_ch=config.out_ch, gpu_ids=config.gpu_ids)\n",
    "\n",
    "    if config.dis_init is not None:\n",
    "        param = torch.load(config.dis_init)\n",
    "        dis.load_state_dict(param)\n",
    "        print('load {} as pretrained model'.format(config.dis_init))\n",
    "\n",
    "    # setup optimizer\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=config.lr, betas=(config.beta1, 0.999), weight_decay=0.00001)\n",
    "    opt_dis = optim.Adam(dis.parameters(), lr=config.lr, betas=(config.beta1, 0.999), weight_decay=0.00001)\n",
    "\n",
    "    real_a = torch.FloatTensor(config.batchsize, config.in_ch, config.width, config.height)\n",
    "    real_b = torch.FloatTensor(config.batchsize, config.out_ch, config.width, config.height)\n",
    "    M = torch.FloatTensor(config.batchsize, config.width, config.height)\n",
    "\n",
    "    criterionL1 = nn.L1Loss()\n",
    "    criterionMSE = nn.MSELoss()\n",
    "    criterionSoftplus = nn.Softplus()\n",
    "\n",
    "    if config.cuda:\n",
    "        gen = gen.cuda()\n",
    "        dis = dis.cuda()\n",
    "        criterionL1 = criterionL1.cuda()\n",
    "        criterionMSE = criterionMSE.cuda()\n",
    "        criterionSoftplus = criterionSoftplus.cuda()\n",
    "        real_a = real_a.cuda()\n",
    "        real_b = real_b.cuda()\n",
    "        M = M.cuda()\n",
    "\n",
    "    real_a = Variable(real_a)\n",
    "    real_b = Variable(real_b)\n",
    "\n",
    "    logreport = LogReport(log_dir=config.out_dir)\n",
    "    validationreport = TestReport(log_dir=config.out_dir)\n",
    "\n",
    "    print('===> begin')\n",
    "    start_time=time.time()\n",
    "    # main\n",
    "    for epoch in range(1, config.epoch + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        for iteration, batch in enumerate(training_data_loader, 1):\n",
    "            real_a_cpu, real_b_cpu, M_cpu = batch[0], batch[1], batch[2]\n",
    "            real_a.data.resize_(real_a_cpu.size()).copy_(real_a_cpu)\n",
    "            real_b.data.resize_(real_b_cpu.size()).copy_(real_b_cpu)\n",
    "            M.data.resize_(M_cpu.size()).copy_(M_cpu)\n",
    "            att, fake_b = gen.forward(real_a)\n",
    "\n",
    "            ################\n",
    "            ### Update D ###\n",
    "            ################\n",
    "            \n",
    "            opt_dis.zero_grad()\n",
    "\n",
    "            # train with fake\n",
    "            fake_ab = torch.cat((real_a, fake_b), 1)\n",
    "            pred_fake = dis.forward(fake_ab.detach())\n",
    "            batchsize, _, w, h = pred_fake.size()\n",
    "\n",
    "            loss_d_fake = torch.sum(criterionSoftplus(pred_fake)) / batchsize / w / h\n",
    "\n",
    "            # train with real\n",
    "            real_ab = torch.cat((real_a, real_b), 1)\n",
    "            pred_real = dis.forward(real_ab)\n",
    "            loss_d_real = torch.sum(criterionSoftplus(-pred_real)) / batchsize / w / h\n",
    "\n",
    "            # Combined loss\n",
    "            loss_d = loss_d_fake + loss_d_real\n",
    "\n",
    "            loss_d.backward()\n",
    "\n",
    "            if epoch % config.minimax == 0:\n",
    "                opt_dis.step()\n",
    "\n",
    "            ################\n",
    "            ### Update G ###\n",
    "            ################\n",
    "            \n",
    "            opt_gen.zero_grad()\n",
    "\n",
    "            # First, G(A) should fake the discriminator\n",
    "            fake_ab = torch.cat((real_a, fake_b), 1)\n",
    "            pred_fake = dis.forward(fake_ab)\n",
    "            loss_g_gan = torch.sum(criterionSoftplus(-pred_fake)) / batchsize / w / h\n",
    "\n",
    "            # Second, G(A) = B\n",
    "            loss_g_l1 = criterionL1(fake_b, real_b) * config.lamb\n",
    "            loss_g_att = criterionMSE(att[:,0,:,:], M)\n",
    "            loss_g = loss_g_gan + loss_g_l1 + loss_g_att\n",
    "\n",
    "            loss_g.backward()\n",
    "\n",
    "            opt_gen.step()\n",
    "\n",
    "            # log\n",
    "            if iteration % 10 == 0:\n",
    "                print(\"===> Epoch[{}]({}/{}): loss_d_fake: {:.4f} loss_d_real: {:.4f} loss_g_gan: {:.4f} loss_g_l1: {:.4f}\".format(\n",
    "                epoch, iteration, len(training_data_loader), loss_d_fake.item(), loss_d_real.item(), loss_g_gan.item(), loss_g_l1.item()))\n",
    "                \n",
    "                log = {}\n",
    "                log['epoch'] = epoch\n",
    "                log['iteration'] = len(training_data_loader) * (epoch-1) + iteration\n",
    "                log['gen/loss'] = loss_g.item()\n",
    "                log['dis/loss'] = loss_d.item()\n",
    "\n",
    "                logreport(log)\n",
    "\n",
    "        print('epoch', epoch, 'finished, use time', time.time() - epoch_start_time)\n",
    "        with torch.no_grad():\n",
    "            log_validation = test(config, validation_data_loader, gen, criterionMSE, epoch)\n",
    "            validationreport(log_validation)\n",
    "        print('validation finished')\n",
    "        if epoch % config.snapshot_interval == 0:\n",
    "            checkpoint(config, epoch, gen, dis)\n",
    "\n",
    "        logreport.save_lossgraph()\n",
    "        validationreport.save_lossgraph()\n",
    "    print('training time:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a501006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spanet():\n",
    "    config = AttrMap(config_dict)\n",
    "    make_manager()\n",
    "    n_job = job_increment()\n",
    "    config.out_dir = os.path.join(config.out_dir, '{:06}'.format(n_job))\n",
    "    os.makedirs(config.out_dir)\n",
    "    print('Job number: {:04d}'.format(n_job))\n",
    "\n",
    "    # 保存本次训练时的配置\n",
    "    shutil.copyfile('config.yml', os.path.join(config.out_dir, 'config.yml'))\n",
    "\n",
    "    train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47142a6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7fcab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "# folder path of dataset, which includes 2 subfolders: cloudy_image/ and ground_truth/\n",
    "'datasets_dir': './data/RICE_DATASET/RICE1/',\n",
    "'train_list': 'train_list.txt',\n",
    "'test_list': 'test_list.txt',\n",
    "'out_dir': 'results',\n",
    "\n",
    "#     edit if there is a GPU\n",
    "'cuda': False,\n",
    "'gpu_ids': None,\n",
    "# gpu_ids: [0]\n",
    "\n",
    "'train_size': 0.8,\n",
    "'validation_size': 0.2,\n",
    "'batchsize': 1,\n",
    "'validation_batchsize': 1,\n",
    "'epoch': 200,\n",
    "'n_data': 300, \n",
    "'width': 512,\n",
    "'height': 512,\n",
    "'threads': 4,\n",
    "\n",
    "'lr': 0.0004,\n",
    "'beta1': 0.5,\n",
    "'lamb': 100,\n",
    "'minimax': 1,\n",
    "\n",
    "'gen_init': None,\n",
    "'dis_init': None,\n",
    "'in_ch': 3,\n",
    "'out_ch': 3,\n",
    "\n",
    "'manualSeed': 0,\n",
    "'snapshot_interval': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d4fef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job number: 0028\n",
      "Random Seed:  0\n",
      "===> Loading datasets\n",
      "dataset: 400\n",
      "train dataset: 320\n",
      "validation dataset: 80\n",
      "===> Loading models\n",
      "===> begin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5625/3912164766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_spanet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5625/2085625352.py\u001b[0m in \u001b[0;36mtrain_spanet\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config.yml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'config.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5625/421609483.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mloss_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_g_gan\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_g_l1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_g_att\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mloss_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/CMSC173/karagatan/capstone/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/CMSC173/karagatan/capstone/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_spanet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98400895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
